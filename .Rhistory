n[grepl("retweet", n)] # "user.followers_count"
d <- fromJSON("data/master_2019.json", flatten=T)
d <- fromJSON("data/master_2009.json", flatten=T)
n <- names(d)
n[grepl("retweet", n)] # "user.followers_count"
n[grepl('follower', n)]
d$text
nrow(d)
d <- fromJSON("data/master_2010.json", flatten=T)
nrow(d)
d <- fromJSON("data/master_2011.json", flatten=T)
nrow(d)
nrow(fromJSON("data/master_2012.json", flatten=T))
nrow(fromJSON("data/master_2013.json", flatten=T))
nrow(fromJSON("data/master_2014.json", flatten=T))
df
d
help(lapply)
df <- data.frame(a=c(NA, 1, 2), b=c(1, NA, 3))
lapply(df, function(x) sum(is.na(x)))
getwd()
# richard
setwd("C:/Users/Richard/Desktop/MSIM Coursework/Winter 2018/INFX 573/Final Project/twitter-hate-speech-identification")
setwd("C:/Users/Richard/Desktop/MSIM Coursework/Winter 2018/INFX 573/Final Project/twitter-hate-speech-identification")
# Install needed packages if necessary
pkgs <- c('jsonlite','tm','SnowballC', 'caTools', 'randomForest','glmnet', 'nnet','ROCR', 'rpart')
for (pkg in pkgs) {
if(!(pkg %in% rownames(installed.packages()))) {
install.packages(pkg)
}
}
# Load the libraries
library(jsonlite)
library(tm)
library(SnowballC)
library(caTools)
library(randomForest)
# Elastic net model paths for some generalized linear models
library(glmnet)
# Multinomial regression
library(nnet)
library (ROCR)
# Library for SVM classifier
library(e1071)
# Classification Tree with rpart
library(rpart)
# Importing the dataset
dataset_original = read.csv('data/labeled_data.csv', sep = ",")
colnames(dataset_original)
rows_original = nrow(dataset_original)
# Import trump tweets to fold into the matrix
keeps <- c("tweet", "created_at", "retweet_count" , "followers_count")
trump_tweet_2017 <- fromJSON("data/master_2017.json", flatten=TRUE)
n = colnames(trump_tweet_2017)
colnames(trump_tweet_2017)[n == 'full_text'] = 'tweet'
colnames(trump_tweet_2017)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2017 = trump_tweet_2017[,keeps]
trump_tweet_2016 <- fromJSON("data/master_2016.json", flatten=TRUE)
n = colnames(trump_tweet_2016)
colnames(trump_tweet_2016)[n == 'text'] = 'tweet'
colnames(trump_tweet_2016)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2016 = trump_tweet_2016[,keeps]
trump_tweet_2015 <- fromJSON("data/master_2015.json", flatten=TRUE)
n = colnames(trump_tweet_2015)
colnames(trump_tweet_2015)[n == 'text'] = 'tweet'
colnames(trump_tweet_2015)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2015 = trump_tweet_2015[,keeps]
trump_tweet_2014 <- fromJSON("data/master_2014.json", flatten=TRUE)
n = colnames(trump_tweet_2014)
colnames(trump_tweet_2014)[n == 'text'] = 'tweet'
colnames(trump_tweet_2014)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2014 = trump_tweet_2014[,keeps]
trump_tweet_2013 <- fromJSON("data/master_2013.json", flatten=TRUE)
n = colnames(trump_tweet_2013)
colnames(trump_tweet_2013)[n == 'text'] = 'tweet'
colnames(trump_tweet_2013)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2013 = trump_tweet_2013[,keeps]
trump_tweet_2012 <- fromJSON("data/master_2012.json", flatten=TRUE)
n = colnames(trump_tweet_2012)
colnames(trump_tweet_2012)[n == 'text'] = 'tweet'
colnames(trump_tweet_2012)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2012 = trump_tweet_2012[,keeps]
trump_tweet_2011 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2011)
colnames(trump_tweet_2011)[n == 'text'] = 'tweet'
colnames(trump_tweet_2011)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2011 = trump_tweet_2011[,keeps]
trump_tweet_2010 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2010)
colnames(trump_tweet_2010)[n == 'text'] = 'tweet'
colnames(trump_tweet_2010)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2010 = trump_tweet_2010[,keeps]
trump_tweet_2009 <- fromJSON("data/master_2009.json", flatten=TRUE)
n = colnames(trump_tweet_2009)
colnames(trump_tweet_2009)[n == 'text'] = 'tweet'
colnames(trump_tweet_2009)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2009 = trump_tweet_2009[,keeps]
trump_tweet = rbind(trump_tweet_2017,trump_tweet_2016,trump_tweet_2015,trump_tweet_2014
,trump_tweet_2013,trump_tweet_2012,trump_tweet_2009)
# "created_at"  "retweet_count" "followers_count" "tweet"
colnames(trump_tweet)
rows_trump = nrow(trump_tweet)
setwd("C:/Users/Richard/Desktop/MSIM Coursework/Winter 2018/INFX 573/Final Project/twitter-hate-speech-identification")
# Install needed packages if necessary
pkgs <- c('jsonlite','tm','SnowballC', 'caTools', 'randomForest','glmnet', 'nnet','ROCR', 'rpart')
for (pkg in pkgs) {
if(!(pkg %in% rownames(installed.packages()))) {
install.packages(pkg)
}
}
# Load the libraries
library(jsonlite)
library(tm)
library(SnowballC)
library(caTools)
library(randomForest)
# Elastic net model paths for some generalized linear models
library(glmnet)
# Multinomial regression
library(nnet)
library (ROCR)
# Library for SVM classifier
library(e1071)
# Classification Tree with rpart
library(rpart)
# Importing the dataset
dataset_original = read.csv('data/labeled_data.csv', sep = ",")
colnames(dataset_original)
rows_original = nrow(dataset_original)
# Import trump tweets to fold into the matrix
keeps <- c("tweet", "created_at", "retweet_count" , "followers_count")
trump_tweet_2017 <- fromJSON("data/master_2017.json", flatten=TRUE)
n = colnames(trump_tweet_2017)
colnames(trump_tweet_2017)[n == 'full_text'] = 'tweet'
colnames(trump_tweet_2017)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2017 = trump_tweet_2017[,keeps]
trump_tweet_2016 <- fromJSON("data/master_2016.json", flatten=TRUE)
n = colnames(trump_tweet_2016)
colnames(trump_tweet_2016)[n == 'text'] = 'tweet'
colnames(trump_tweet_2016)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2016 = trump_tweet_2016[,keeps]
trump_tweet_2015 <- fromJSON("data/master_2015.json", flatten=TRUE)
n = colnames(trump_tweet_2015)
colnames(trump_tweet_2015)[n == 'text'] = 'tweet'
colnames(trump_tweet_2015)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2015 = trump_tweet_2015[,keeps]
trump_tweet_2014 <- fromJSON("data/master_2014.json", flatten=TRUE)
n = colnames(trump_tweet_2014)
colnames(trump_tweet_2014)[n == 'text'] = 'tweet'
colnames(trump_tweet_2014)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2014 = trump_tweet_2014[,keeps]
trump_tweet_2013 <- fromJSON("data/master_2013.json", flatten=TRUE)
n = colnames(trump_tweet_2013)
colnames(trump_tweet_2013)[n == 'text'] = 'tweet'
colnames(trump_tweet_2013)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2013 = trump_tweet_2013[,keeps]
trump_tweet_2012 <- fromJSON("data/master_2012.json", flatten=TRUE)
n = colnames(trump_tweet_2012)
colnames(trump_tweet_2012)[n == 'text'] = 'tweet'
colnames(trump_tweet_2012)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2012 = trump_tweet_2012[,keeps]
trump_tweet_2011 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2011)
colnames(trump_tweet_2011)[n == 'text'] = 'tweet'
colnames(trump_tweet_2011)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2011 = trump_tweet_2011[,keeps]
trump_tweet_2010 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2010)
colnames(trump_tweet_2010)[n == 'text'] = 'tweet'
colnames(trump_tweet_2010)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2010 = trump_tweet_2010[,keeps]
trump_tweet_2009 <- fromJSON("data/master_2009.json", flatten=TRUE)
n = colnames(trump_tweet_2009)
colnames(trump_tweet_2009)[n == 'text'] = 'tweet'
colnames(trump_tweet_2009)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2009 = trump_tweet_2009[,keeps]
trump_tweet = rbind(trump_tweet_2017,trump_tweet_2016,trump_tweet_2015,trump_tweet_2014
,trump_tweet_2013,trump_tweet_2012,trump_tweet_2009)
# "created_at"  "retweet_count" "followers_count" "tweet"
colnames(trump_tweet)
rows_trump = nrow(trump_tweet)
nrow(trump_tweet)
write.csv("All Trump Tweets.csv", row.names=F)
write.csv(trump_tweet, "All Trump Tweets.csv", row.names=F)
names(trump_pred)
head(trump_tweet)
row.names(trump_tweet)
row.names(trump_tweet)[1:5]
diff(as.numeric(row.names(trump_tweet)))[1:5]
sum(diff(as.numeric(row.names(trump_tweet)))!=1)
sum(diff(as.numeric(names(trump_pred))))
sum(diff(as.numeric(names(trump_pred)))!=1)
diff(c(4,3,2))
names(trump_tweet)
names(all_tweets)
names(recent)
names(dataset_original)
names(trump_tweet)
# Predict trumps tweet
trump_pred = predict(classifier, newdata = trump.dtm)
recent_pred = predict(classifier, newdata = recent.dtm)
trump_tweet$class = trump_pred
setwd("C:/Users/Richard/Desktop/MSIM Coursework/Winter 2018/INFX 573/Final Project/twitter-hate-speech-identification")
# Install needed packages if necessary
pkgs <- c('jsonlite','tm','SnowballC', 'caTools', 'randomForest','glmnet', 'nnet','ROCR', 'rpart')
for (pkg in pkgs) {
if(!(pkg %in% rownames(installed.packages()))) {
install.packages(pkg)
}
}
# Load the libraries
library(jsonlite)
library(tm)
library(SnowballC)
library(caTools)
library(randomForest)
# Elastic net model paths for some generalized linear models
library(glmnet)
# Multinomial regression
library(nnet)
library (ROCR)
# Library for SVM classifier
library(e1071)
# Classification Tree with rpart
library(rpart)
# Importing the dataset
dataset_original = read.csv('data/labeled_data.csv', sep = ",")
colnames(dataset_original)
rows_original = nrow(dataset_original)
# Import trump tweets to fold into the matrix
keeps <- c("tweet", "created_at", "retweet_count" , "followers_count")
trump_tweet_2017 <- fromJSON("data/master_2017.json", flatten=TRUE)
n = colnames(trump_tweet_2017)
colnames(trump_tweet_2017)[n == 'full_text'] = 'tweet'
colnames(trump_tweet_2017)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2017 = trump_tweet_2017[,keeps]
trump_tweet_2016 <- fromJSON("data/master_2016.json", flatten=TRUE)
n = colnames(trump_tweet_2016)
colnames(trump_tweet_2016)[n == 'text'] = 'tweet'
colnames(trump_tweet_2016)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2016 = trump_tweet_2016[,keeps]
trump_tweet_2015 <- fromJSON("data/master_2015.json", flatten=TRUE)
n = colnames(trump_tweet_2015)
colnames(trump_tweet_2015)[n == 'text'] = 'tweet'
colnames(trump_tweet_2015)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2015 = trump_tweet_2015[,keeps]
trump_tweet_2014 <- fromJSON("data/master_2014.json", flatten=TRUE)
n = colnames(trump_tweet_2014)
colnames(trump_tweet_2014)[n == 'text'] = 'tweet'
colnames(trump_tweet_2014)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2014 = trump_tweet_2014[,keeps]
trump_tweet_2013 <- fromJSON("data/master_2013.json", flatten=TRUE)
n = colnames(trump_tweet_2013)
colnames(trump_tweet_2013)[n == 'text'] = 'tweet'
colnames(trump_tweet_2013)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2013 = trump_tweet_2013[,keeps]
trump_tweet_2012 <- fromJSON("data/master_2012.json", flatten=TRUE)
n = colnames(trump_tweet_2012)
colnames(trump_tweet_2012)[n == 'text'] = 'tweet'
colnames(trump_tweet_2012)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2012 = trump_tweet_2012[,keeps]
trump_tweet_2011 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2011)
colnames(trump_tweet_2011)[n == 'text'] = 'tweet'
colnames(trump_tweet_2011)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2011 = trump_tweet_2011[,keeps]
trump_tweet_2010 <- fromJSON("data/master_2011.json", flatten=TRUE)
n = colnames(trump_tweet_2010)
colnames(trump_tweet_2010)[n == 'text'] = 'tweet'
colnames(trump_tweet_2010)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2010 = trump_tweet_2010[,keeps]
trump_tweet_2009 <- fromJSON("data/master_2009.json", flatten=TRUE)
n = colnames(trump_tweet_2009)
colnames(trump_tweet_2009)[n == 'text'] = 'tweet'
colnames(trump_tweet_2009)[n == 'user.followers_count'] = 'followers_count'
trump_tweet_2009 = trump_tweet_2009[,keeps]
trump_tweet = rbind(trump_tweet_2017,trump_tweet_2016,trump_tweet_2015,trump_tweet_2014
,trump_tweet_2013,trump_tweet_2012,trump_tweet_2009)
# "created_at"  "retweet_count" "followers_count" "tweet"
colnames(trump_tweet)
rows_trump = nrow(trump_tweet)
# Import random tweets fold into the matrix
# feb 17-24 2018
recent = read.csv("random tweets.csv")
colnames(recent)
rows_recent = nrow(recent)
# Joined dataset
d1 = data.frame((as.factor(dataset_original$tweet)))
colnames(d1) = "tweet"
d2 = data.frame((as.factor(trump_tweet$tweet)))
colnames(d2) = "tweet"
d3 = data.frame(as.factor(recent$Text))
colnames(d3) = "tweet"
all_tweets = rbind(d1,d2,d3)
# Create a corpus
library(stringr)
all_tweets$tweet <- str_replace_all(all_tweets$tweet,"([^A-Za-z0-9 ])+", " ")
corpus = VCorpus(VectorSource(all_tweets$tweet))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Creating the Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
# Split original labeled and new tweets
training = dataset[1:rows_original,]
trump.dtm = dataset[(rows_original+1):(rows_original+rows_trump),]
recent.dtm = dataset[(rows_original+rows_trump +1):(rows_original+rows_trump+rows_recent),]
# Encoding the target feature as a factor
response = dataset_original$class
response = factor(dataset_original$class, levels = c(0, 1, 2))
# Target variable / true classification of the tweet
# Splitting the dataset into the Training set and Test set
set.seed(1)
#split = sample.split(dataset$class, SplitRatio = 0.8)
#training_set = subset(dataset, split == TRUE)
#test_set = subset(dataset, split == FALSE)
#numCol = ncol(training_set)
# Fitting Several different classifiers on the training set
t1 = Sys.time()
# Random forest classifier
classifier = randomForest(x = training,
y = response,
ntree = 1)
trump_pred = predict(classifier, newdata = trump.dtm)
recent_pred = predict(classifier, newdata = recent.dtm)
trump_tweet$class = trump_pred
recent$class = recent_pred
# Verify rows match input trump tweet data
sum(diff(as.numeric(names(trump_pred)))!=1) # good!
table(trump_tweet$class)
lapply(table(trump_tweet$class), function(x) x/nrow(trump_tweet))
as.data.frame(lapply(table(trump_tweet$class), function(x) x/nrow(trump_tweet)))
as.data.frame(lapply(table(trump_tweet$class), function(x) x/nrow(trump_tweet)), .names=c('0', '1', '2'))
as.data.frame(lapply(table(trump_tweet$class), function(x) x/nrow(trump_tweet)), .Names=c('0', '1', '2'))
as.data.frame(lapply(table(trump_tweet$class), function(x) x/nrow(trump_tweet)))
names(trump_tweet)
head(trump_tweet$created_at)
typeof(trump_tweet$created_at)
# Get dates
dt <- "Mon Jan 01 13:37:52 +0000 2018"
strsplit(dt, ' ')
t(as.data.frame(strsplit(dt, ' ')))
as.data.frame(strsplit(dt, ' '))
as.data.frame(strsplit(dt, ' '))[1,]
strsplit(dt, ' ')
unlist(strsplit(dt, ' '))
year <- unlist(strsplit(dt, ' '))[6]
year
months <- paste('0', 1:9, sep='')
months
months <- c(paste('0', 1:9, sep=''),'10','11','12')
months
months[mo=='Apr']
# Get dates
mo <- c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')
months[mo=='Apr']
dt_parts <- unlist(strsplit(dt, ' '))
dt_parts
dt_parts[2]
month <- months[mo==dt_parts[2]]
month
dtime <- dt_parts[4]
dt <- "Mon Jan 01 13:37:52 +0000 2018"
dt_parts <- unlist(strsplit(dt, ' '))
year <- dt_parts[6]
month <- months[mo==dt_parts[2]]
day <- dt_parts[3]
dtime <- dt_parts[4]
dtparts <- t(as.data.frame(strsplit("2002-06-09 12:45:40", ' ')))
row.names(dtparts)=NULL
dtparts[,1]
paste(year,month,day,sep='-')
# yy-mm-dd h:m:s
datetime <- chron(dates=paste(year,month,day,sep='-'), times=dtime)
library(chron)
install.packages("chron")
library(chron)
# yy-mm-dd h:m:s
datetime <- chron(dates=paste(year,month,day,sep='-'), times=dtime)
# yy-mm-dd h:m:s
datetime <- chron(dates=paste(year,month,day,sep='-'), times=dtime, format=c('y-m-d', 'h:m:s'))
datetime
sapply(1:10, function(x) datetime + x)
datetime+10
sapply(1:10, function(x) datetime)
as.numeric(datetime)
trump_tweet$created_at[1]
df
df$x <- c('hi bye', 'me me', 'lol lol bye')
unlist(strsplit(df$x, ' '))
sapply(df$x, function(x) strsplit(x, ' '))
sapply(df$x, function(x) unlist(strsplit(x, ' ')))
# Make datetime field
dt_parts <- sapply(trump_tweet$created_at, function(row) strsplit(row, ' '))
dt_parts[1]
dt_parts <- sapply(trump_tweet$created_at, function(row) strsplit(row, ' '))
year <- dt_parts[6]
month <- months[mo==dt_parts[2]]
day <- dt_parts[3]
dtime <- dt_parts[4]
# Call it 'dt_num'
trump_tweet$dt_num <- as.numeric(chron(dates=paste(year,month,day,sep='-'), times=dtime,
format=c('y-m-d', 'h:m:s')))
dt_parts[1]
year <- lapply(dt_parts, function(part) part[6])
year[1]
year[2]
year[200]
year <- unlist(lapply(dt_parts, function(part) part[6]))
year
year[1]
unname(year[1])
year[1]
paste(year[1], 'hi')
month <- unlist(lapply(dt_parts, function(part) months[mo==part[2]]))
dt_parts <- sapply(trump_tweet$created_at, function(row) strsplit(row, ' '))
year  <- unlist(lapply(dt_parts, function(part) part[6]))
month <- unlist(lapply(dt_parts, function(part) months[mo==part[2]]))
day   <- unlist(lapply(dt_parts, function(part) part[3]))
dtime <- unlist(lapply(dt_parts, function(part) part[4]))
trump_tweet$dt_num <- as.numeric(chron(dates=paste(year,month,day,sep='-'), times=dtime,
format=c('y-m-d', 'h:m:s')))
trump_tweet[1]
trump_tweet$dt_num[1]
trump_tweet[,c("created_at", "dt_num")][200:202]
names(trump_tweet)
trump_tweet[,"created_at"][200:202]
trump_tweet[,"dt_num"][200:202]
chron(dates='17-12-01',times='03:30:42')
chron(dates='17-12-01',times='03:30:42', format='y-m-d h:m:s')
chron(dates='17-12-01',times='03:30:42', format='y-m-d', 'h:m:s')
chron(dates='17-12-01',times='03:30:42', format=('y-m-d', 'h:m:s'))
chron(dates='17-12-01',times='03:30:42', format=c('y-m-d', 'h:m:s'))
chron(dates='17-12-01',times='03:30:42', format=c('y-m-d', 'h:m:s'))-17501.15
as.numeric(chron(dates='17-12-01',times='03:30:42', format=c('y-m-d', 'h:m:s'))-17501.15)
trump_tweet$dt_num[1]
names(trump_tweet)
plot(trump_tweet$dt_num, trump_tweet$followers_count)
min(trump_tweet$followers_count)
as.chron(17532.57)
df
with(df) { print(a)}
within(df) { print(a)}
help(within)
with(df, a)
with(df, plot(a))
# Plot stuff against time
with(trump_tweet, plot(dt_num, followers_count))
with(trump_tweet, followers_count[dt_num > 15000 & dt_num < 15100])
with(trump_tweet, followers_count[dt_num > 15500 & dt_num < 15900])
# Can call as.chron(dt_num) to get date-looking things back
as.chron(17000)
# Plot stuff against time
with(trump_tweet[,"dt_num">17000, plot(dt_num, followers_count))
# Plot stuff against time
with(subset(trump_tweet, dt_num>17000), plot(dt_num, followers_count))
sample(trump_tweet$dt_num, 10)
help(seq)
length(trump_tweet$dt_num)
nrow(trump_tweet)
tail(seq(0, nrow(trump_tweet), by=30))
with(trump_tweet[seq(0,nrow(trump_tweet),by=30),], plot(dt_num, followers_count))
with(trump_tweet[seq(0,nrow(trump_tweet),by=60),], plot(dt_num, followers_count))
with(tt, plot(dt_num, followers_count))
# Plot stuff against time
tt <- trump_tweet[seq(0,nrow(tt),by=60)]
with(subset(tt, dt_num>17000), plot(dt_num, followers_count))
# Plot stuff against time
tt <- trump_tweet[seq(0,nrow(tt),by=60)]
# Plot stuff against time
tt <- trump_tweet
tt <- tt[seq(0,nrow(tt),by=60)]
with(subset(tt, dt_num>17000), plot(dt_num, followers_count))
max(tt$dt_num)-min(tt$dt_num)
3163.78/30
tt <- tt[seq(0,nrow(tt),by=60),]
with(subset(tt, dt_num>17000), plot(dt_num, followers_count))
tt <- tt[seq(0,nrow(tt),by=30),]
chron('11/08/16')
chron('11/08/16', '13:00:00')
as.numeric(chron('11/08/16', '13:00:00'))
as.chron(17110)
as.chron(17113)
abline(17113, col='red', lwd=2)
abline(v=17113, col='red', lwd=2)
chron('06-16-15')
chron('06/16/15')
as.numeric(chron('06/16/15'))
as.numeric(chron('05/03/16')) # Became presumptive nominee
as.chron(17113)
abline(v=as.numeric(chron('11/08/16')), col='red', lwd=2)
with(subset(tt, dt_num>16500), plot(dt_num, followers_count))
max(tt$dt_num)
tt <- tt[seq(0,nrow(tt),by=10),]
with(subset(tt, dt_num>16500), plot(dt_num, followers_count))
# Plot stuff against time
tt <- trump_tweet
tt <- trump_tweet[seq(0,nrow(trump_tweet),by=10),]
with(subset(tt, dt_num>16500), plot(dt_num, followers_count))
abline(v=as.numeric(chron('11/08/16')), col='red', lwd=2)
abline(v=as.numeric(chron('06/16/15')), col='red', lwd=2) # Presidential Bid
abline(v=as.numeric(chron('05/03/16')), col='red', lwd=2) # Became presumptive nominee
abline(v=as.numeric(chron('11/08/16')), col='purple', lwd=2) # Election
abline(v=as.numeric(chron('06/16/15')), col='blue', lwd=2) # Presidential Bid
abline(v=as.numeric(chron('05/03/16')), col='red', lwd=2) # Became presumptive nominee
names(tt)
with(tt, plot(dt_num, retweet_count, add=T))
